1. 数学公式
The Mathematical Formula
For a normalized value x where 1 ≤ x < 2, the fractional part of log₂(x) can be calculated as:
log₂(x) = Σ(i=1 to n) d_i × 2^(-i)
Where:
d_i = 1 if x^(2^i) ≥ 2, otherwise d_i = 0
n is the number of bits of precision desired


2. 示例
# Log₂ Iterative Approximation for Fractional Part

Yes, the code uses an iterative approximation algorithm to compute the fractional part of log₂. Let me explain the mathematical formula and provide a simple example.

## The Mathematical Formula

For a normalized value x where 1 ≤ x < 2, the fractional part of log₂(x) can be calculated as:

log₂(x) = Σ(i=1 to n) d_i × 2^(-i)

Where:
- d_i = 1 if x^(2^i) ≥ 2, otherwise d_i = 0
- n is the number of bits of precision desired

## The Algorithm in Steps

1. Start with a normalized value x (1 ≤ x < 2)
2. Initialize result = 0
3. For each bit position i from 1 to n:
   - Square x: x = x²
   - If x ≥ 2:
     - Add 2^(-i) to result
     - Divide x by 2
   - Move to next bit position

## Simple Example: Calculate log₂(1.5)

Let's calculate log₂(1.5) using this algorithm:

### Setup
- x = 1.5 (already normalized since 1 ≤ x < 2)
- result = 0
- We'll calculate 4 bits of precision

### Iteration 1: i = 1, bit value = 2^(-1) = 0.5
1. Square x: x² = 1.5² = 2.25
2. Is x² ≥ 2? Yes (2.25 > 2)
3. Add 0.5 to result: result = 0 + 0.5 = 0.5
4. Divide x² by 2: x = 2.25 ÷ 2 = 1.125

### Iteration 2: i = 2, bit value = 2^(-2) = 0.25
1. Square x: x² = 1.125² = 1.265625
2. Is x² ≥ 2? No (1.265625 < 2)
3. Result remains: result = 0.5
4. x remains: x = 1.265625

### Iteration 3: i = 3, bit value = 2^(-3) = 0.125
1. Square x: x² = 1.265625² = 1.6017913818359375
2. Is x² ≥ 2? No (1.6017913818359375 < 2)
3. Result remains: result = 0.5
4. x remains: x = 1.6017913818359375

### Iteration 4: i = 4, bit value = 2^(-4) = 0.0625
1. Square x: x² = 1.6017913818359375² ≈ 2.5657
2. Is x² ≥ 2? Yes (2.5657 > 2)
3. Add 0.0625 to result: result = 0.5 + 0.0625 = 0.5625
4. Divide x² by 2: x = 2.5657 ÷ 2 ≈ 1.2829

### Final Result
After 4 iterations, our approximation of log₂(1.5) is 0.5625.

The actual value of log₂(1.5) ≈ 0.5850, so with just 4 iterations we're already quite close!

## How This Maps to the Code

```rust
// Initialize
let mut bit: i128 = 0x8000_0000_0000_0000i128;  // 0.5 in Q64.64
let mut log2p_fraction_x64 = 0;                 // Result accumulator
let mut r = /* normalized value */;             // Input value normalized to [1,2)

// Iterative approximation
while bit > 0 && precision < BIT_PRECISION {
    r *= r;                                     // Square r
    let is_r_more_than_two = r >> 127 as u32;   // Check if r² ≥ 2
    r >>= 63 + is_r_more_than_two;              // Normalize r again
    log2p_fraction_x64 += bit * is_r_more_than_two as i128;  // Add bit if r² ≥ 2
    bit >>= 1;                                  // Move to next bit
    precision += 1;                             // Track precision
}
```

## Why This Algorithm Works

This algorithm effectively builds the binary representation of log₂(x) bit by bit:
- Each iteration determines one binary digit
- The test "is x² ≥ 2?" determines if that digit is 0 or 1
- The algorithm converges to the exact value as precision increases

This approach is particularly well-suited for fixed-point arithmetic because:
1. It uses only multiplication, comparison, and bit operations
2. It avoids floating-point operations entirely
3. It produces deterministic results with controlled precision
4. It can be efficiently implemented in hardware or software

The mathematical insight behind this algorithm is that taking logarithms can be transformed into a series of squaring operations and comparisons, which are much simpler to implement in digital systems.
